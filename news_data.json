import requests
from bs4 import BeautifulSoup
import json
import datetime

def fetch_news():
    sources = [
        "https://www.mot.gov.cn/",
        "http://www.nea.gov.cn/",
        "http://www.chinawuliu.com.cn/",
        "https://www.evpartner.com/",
        "https://www.itf-oecd.org/",
        "https://www.freightwaves.com/",
        "https://www.reuters.com/business/autos-transportation/",
        "https://www.greencarcongress.com/"
    ]
    headers = {"User-Agent": "Mozilla/5.0"}
    news_list = []
    
    for url in sources:
        response = requests.get(url, headers=headers)
        if response.status_code != 200:
            print(f"Failed to fetch news from {url}")
            continue
        
        soup = BeautifulSoup(response.text, "html.parser")
        articles = soup.find_all("article")
        
        for article in articles:
            title = article.find("h2").text if article.find("h2") else "No Title"
            link = article.find("a")["href"] if article.find("a") else "#"
            date = datetime.datetime.now().strftime("%Y-%m-%d")
            category = "Industry News" if "logistics" in url else "Policy"
            
            news_list.append({
                "title": title,
                "link": link,
                "date": date,
                "category": category
            })
    
    return news_list

def save_news(news_list):
    with open("news_data.json", "w", encoding="utf-8") as file:
        json.dump(news_list, file, indent=4, ensure_ascii=False)

def main():
    news_list = fetch_news()
    save_news(news_list)
    print(f"Fetched {len(news_list)} news articles.")

if __name__ == "__main__":
    main()
